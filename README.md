# AR/VR Clustering Case Study

This project is a complete hands-on case study applying unsupervised learning techniques such as **KMeans**, **DBSCAN**, **PCA**, and **t-SNE** to synthetic data, real-world images, and sensor data. It simulates practical use cases in AR/VR environments including image segmentation, sensor clustering, and visual overlays.

The entire project is implemented in a single Jupyter notebook and is designed to run on CPU using Google Colab.

---

## Tasks Covered

| Task | Description |
|------|-------------|
| 1 | Clustering on synthetic 2D data using KMeans and DBSCAN |
| 2 | Image segmentation using KMeans |
| 3 | Dimensionality reduction with PCA and t-SNE |
| 4 | Clustering sensor data to detect user activity |
| 5 | Overlaying clustering results on images (AR simulation) |
| 6 | Cloning and running a real-world GitHub project (KMeans segmentation) |

---

## Project Files

| File | Description |
|------|-------------|
| `AR_VR_Clustering_CaseStudy.ipynb` | Main notebook containing all six tasks |
| `README.md` | Project overview and documentation |
| `sample_images/` | Folder containing images used in segmentation tasks |

---

## How to Run

Open the notebook in Google Colab:

[Open in Colab](https://colab.research.google.com/github/YOUR_USERNAME/AR-VR-Clustering-CaseStudy/blob/main/AR_VR_Clustering_CaseStudy.ipynb)

No GPU required. All tasks are optimized for CPU.

---

## Libraries and Tools

- Python 3.x
- Scikit-learn
- OpenCV
- NumPy
- Matplotlib
- Google Colab

---

## Conclusion

This case study demonstrates how unsupervised learning techniques can be used to analyze, cluster, and visualize data in AR/VR contexts. By experimenting with clustering, dimensionality reduction, and image processing, this project builds foundational skills for intelligent input interpretation without labeled data.

---

